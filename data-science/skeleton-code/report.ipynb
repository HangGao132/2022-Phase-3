{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Data Science Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the 10 labels are used. The model will output an array with the length of 10, and each digit represent the label of image. It will mark the possibility of each label that the image is of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model contains various layers stacked on top of each other. The output of one layer feeds into the input of the next layer.\n",
    "\n",
    "Conv2D layers are convolutions. Each filter (32 in the first two convolution layers and 64 in the next two convolution layers) transforms a part of the image (5x5 for the first two Conv2D layers and 3x3 for the next two Conv2D layers). The transformation is applied on the whole image.\n",
    "\n",
    "MaxPool2D is a downsampling filter. It reduces a 2x2 matrix of the image to a single pixel with the maximum value of the 2x2 matrix. The filter aims to conserve the main features of the image while reducing the size.\n",
    "\n",
    "Dropout is a regularization layer. In this model, 25% of the nodes in the layer are randomly ignores, allowing the network to learn different features. This prevents overfitting.\n",
    "\n",
    "relu is the rectifier, and it is used to find nonlinearity in the data. It works by returning the input value if the input value >= 0. If the input is negative, it returns 0.\n",
    "\n",
    "Flatten converts the tensors into a 1D vector.\n",
    "\n",
    "The Dense layers are an artificial neural network (ANN). The last layer returns the probability that an image is in each class (one for each digit).\n",
    "\n",
    "As this model aims to categorize the images, will use a categorical_crossentropy loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained 70 epoch and the loss was 0.5510, accuracy 0.8038.\n",
    "\n",
    "Using the test dataset, and the validation loss was 0.6949, validation accuracy 0.7647.\n",
    "\n",
    "The results is good, but still have problems classifying cats and dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy will get higher with more training epoches. And it is not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. [Learning Multiple Layers of Features from Tiny Images](http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf), Alex Krizhevsky, 2009."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e057365759ce64748f45be5b74d3c1d08d296b4c0e8363ba1822990142ab9c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
